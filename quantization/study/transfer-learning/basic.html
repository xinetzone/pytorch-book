
<!DOCTYPE html>

<html lang="zh_CN">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>计算机视觉分类 &#8212; Pytorch Book 0.0.1 文档</title>
    
  <link href="../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/style.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/default.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="shortcut icon" href="../../../_static/favicon.jpg"/>
    <link rel="index" title="索引" href="../../../genindex.html" />
    <link rel="search" title="搜索" href="../../../search.html" />
    <link rel="next" title="量化计算机视觉分类" href="quantized.html" />
    <link rel="prev" title="迁移学习" href="index.html" />
    <link rel="stylesheet" href="../../../_static/css/default.css"/>
    <link rel="stylesheet" href="../../../_static/css/custom.css"/>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../index.html">
  <img src="../../../_static/logo.jpg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../intro.html">
  项目简介
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../tutorials/index.html">
  教程
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../index.html">
  量化
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../ecosystem/index.html">
  生态系统
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../api/index.html">
  API 参考
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../refs.html">
  参考文献
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../others/index.html">
  其他
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/xinetzone/pytorch-book" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../start/index.html">
   快速上手
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../start/basic.html">
     基础
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../start/ns.html">
     Pytorch 数值套件教程
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../index.html">
   学习
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../intro.html">
     概述
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="index.html">
     迁移学习
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       计算机视觉分类
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="quantized.html">
       量化计算机视觉分类
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="tvm.html">
       TVM
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="test.html">
       测试
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../qat-resnet18.html">
     QAT（resnet18）
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../qat-mini.html">
     静态量化（cifar10）
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../papers/index.html">
   论文
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../papers/gholami2021survey.html">
     A Survey of Quantization Methods for Efficient Neural Network Inference
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../api/index.html">
   量化 API
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../api/runner.html">
     runner
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../api/generated/runner.Timer.html">
       runner.Timer
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../api/generated/runner.Accumulator.html">
       runner.Accumulator
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../api/generated/runner.Animator.html">
       runner.Animator
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../api/generated/runner.show_images.html">
       runner.show_images
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../api/xinet.html">
     xinet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../api/net.html">
     NN 模块
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../api/helper.html">
     辅助工具
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../api/tools.html">
     工具
    </a>
   </li>
  </ul>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convnet">
   微调 ConvNet
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   ConvNet 作为固定的特征提取器
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                

<div class="tocsection editthispage">
    <a href="https://github.com/xinetzone/pytorch-book/edit/main/docs/quantization/study/transfer-learning/basic.ipynb">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1>计算机视觉分类<a class="headerlink" href="#id1" title="永久链接至标题">¶</a></h1>
<p>在本教程中，您将学习如何使用迁移学习训练卷积神经网络进行图像分类。你可以在 <a class="reference external" href="https://cs231n.github.io/transfer-learning/">cs231n notes</a> 中阅读更多关于迁移学习的信息。</p>
<div class="admonition note">
<p class="admonition-title">备注</p>
<p>在实践中，很少有人从零开始（使用随机初始化）训练整个卷积网络，因为拥有足够大的数据集是相对罕见的。相反，通常是在非常大的数据集（例如 ImageNet，包含 120 万张包含 1000 个类别的图像）上预训练卷积神经网络，然后使用卷积神经网络作为初始化或用于感兴趣的任务的固定特征提取器。</p>
</div>
<p>这两种主要的迁移学习场景如下：</p>
<ol class="simple">
<li><p><strong>微调 ConvNet</strong>：该模型不是随机初始化，而是使用预训练的网络初始化，之后的训练照常进行，但使用不同的数据集。如果有不同数量的输出，通常也替换网络中的头（或它的一部分）。在这种方法中，通常将学习速率设置为较小的数值。之所以这样做，是因为网络已经经过了训练，只需要稍作修改就可以将其“微调”到新的数据集。</p></li>
<li><p><strong>ConvNet 作为固定的特征提取器</strong>：在这里，你 <a class="reference external" href="https://arxiv.org/abs/1706.04983">“冻结”</a> 除了最后几个层（又名“头部”，通常是全连接的层）之外，网络中所有参数的权重。这些最后的层将被替换为新层，并初始化为随机权重，只有这些层会被训练。</p></li>
</ol>
<p>你也可以将以上两种方法结合使用：首先，你可以冻结特征提取器，训练头部。在此之后，您可以解冻特征提取器（或部分特征提取器），将学习速率设置为较小的值，然后继续训练。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">lr_scheduler</span>
<span class="kn">from</span> <span class="nn">torch.backends</span> <span class="kn">import</span> <span class="n">cudnn</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># 让程序在开始时花费一点额外时间，</span>
<span class="c1"># 为整个网络的每个卷积层搜索最适合它的卷积实现算法，进而实现网络的加速。</span>
<span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>   <span class="c1"># 交互模式</span>

<span class="c1"># 载入自定义模块</span>
<span class="kn">from</span> <span class="nn">mod</span> <span class="kn">import</span> <span class="n">load_mod</span>
<span class="n">load_mod</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition- admonition">
<p class="admonition-title">任务</p>
<p>训练对蚂蚁和蜜蜂进行分类的模型。</p>
</div>
<p class="rubric">加载数据</p>
<p>通常，如果从零开始训练，这是一个非常小的可泛化的数据集。由于使用迁移学习，应该能够相当好地推广。</p>
<p>本文自定义数据加载器 <code class="xref py py-class docutils literal notranslate"><span class="pre">Hymenoptera</span></code>：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_book.datasets.examples</span> <span class="kn">import</span> <span class="n">Hymenoptera</span>
<span class="c1"># 加载数据</span>
<span class="n">loader</span> <span class="o">=</span> <span class="n">Hymenoptera</span><span class="p">(</span><span class="s1">&#39;data/hymenoptera_data&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p class="rubric">训练模型</p>
<p>写一个通用函数 <code class="xref py py-func docutils literal notranslate"><span class="pre">train_model()</span></code> 来训练模型：</p>
<ul class="simple">
<li><p>调度学习率</p></li>
<li><p>保存最佳模型</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tools</span> <span class="kn">import</span> <span class="n">train_model</span>
</pre></div>
</div>
</div>
</div>
<p class="rubric">可视化模型预测</p>
<p><code class="xref py py-meth docutils literal notranslate"><span class="pre">imshow()</span></code> 显示预测的一些图像的通用函数：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">xinet</span> <span class="kn">import</span> <span class="n">ModuleTool</span><span class="p">,</span> <span class="n">CV</span>
</pre></div>
</div>
</div>
</div>
<p class="rubric">设置设备</p>
<p>设置模型训练的设备：</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:1&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="convnet">
<h2>微调 ConvNet<a class="headerlink" href="#convnet" title="永久链接至标题">¶</a></h2>
<p>加载预训练模型，重置最终的全连接层。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_ft</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">num_ftrs</span> <span class="o">=</span> <span class="n">model_ft</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="c1"># 这里每个输出样本的大小设置为 2。</span>
<span class="c1"># 或者，它可以推广到 ``nn.Linear(num_ftrs, len(class_names))``。</span>
<span class="n">model_ft</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_ftrs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># 观测所有被优化的参数</span>
<span class="n">optimizer_ft</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_ft</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># Decay LR by a factor of 0.1 every 7 epochs</span>
<span class="n">exp_lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_ft</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p class="rubric">训练和评估</p>
<p>在 CPU 上应该需要大约 15-25 分钟。而在 GPU 上，这只需要不到一分钟的时间。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_iter</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
<span class="n">test_iter</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">]</span>
<span class="n">CV</span><span class="o">.</span><span class="n">train_fine_tuning</span><span class="p">(</span><span class="n">model_ft</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span>
                     <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                     <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
                     <span class="n">param_group</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AttributeError</span><span class="g g-Whitespace">                            </span>Traceback (most recent call last)
<span class="nn">/media/pc/data/4tb/xinet/web/pytorch-book/docs/quantization/study/transfer-learning/basic.ipynb Cell 15&#39;</span> in <span class="ni">&lt;cell line: 3&gt;</span><span class="nt">()</span>
      <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/4tb/xinet/web/pytorch-book/docs/quantization/study/transfer-learning/basic.ipynb#ch0000014vscode-remote?line=0&#39;</span><span class="o">&gt;</span><span class="mi">1</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">train_iter</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span>
      <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/4tb/xinet/web/pytorch-book/docs/quantization/study/transfer-learning/basic.ipynb#ch0000014vscode-remote?line=1&#39;</span><span class="o">&gt;</span><span class="mi">2</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">test_iter</span> <span class="o">=</span> <span class="n">loader</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">]</span>
<span class="o">----&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/4tb/xinet/web/pytorch-book/docs/quantization/study/transfer-learning/basic.ipynb#ch0000014vscode-remote?line=2&#39;</span><span class="o">&gt;</span><span class="mi">3</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">CV</span><span class="o">.</span><span class="n">train_fine_tuning</span><span class="p">(</span><span class="n">model_ft</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span>
      <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/4tb/xinet/web/pytorch-book/docs/quantization/study/transfer-learning/basic.ipynb#ch0000014vscode-remote?line=3&#39;</span><span class="o">&gt;</span><span class="mi">4</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>                      <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
      <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/4tb/xinet/web/pytorch-book/docs/quantization/study/transfer-learning/basic.ipynb#ch0000014vscode-remote?line=4&#39;</span><span class="o">&gt;</span><span class="mi">5</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>                      <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
      <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/4tb/xinet/web/pytorch-book/docs/quantization/study/transfer-learning/basic.ipynb#ch0000014vscode-remote?line=5&#39;</span><span class="o">&gt;</span><span class="mi">6</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>                      <span class="n">param_group</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nn">File /media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py:256,</span> in <span class="ni">CV.train_fine_tuning</span><span class="nt">(net, train_iter, test_iter, learning_rate, num_epochs, param_group)</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=252&#39;</span><span class="o">&gt;</span><span class="mi">253</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="k">else</span><span class="p">:</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=253&#39;</span><span class="o">&gt;</span><span class="mi">254</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">trainer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=254&#39;</span><span class="o">&gt;</span><span class="mi">255</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>                               <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="o">--&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=255&#39;</span><span class="o">&gt;</span><span class="mi">256</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">CV</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=256&#39;</span><span class="o">&gt;</span><span class="mi">257</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>          <span class="n">loss</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=257&#39;</span><span class="o">&gt;</span><span class="mi">258</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>          <span class="n">devices</span><span class="p">)</span>

<span class="nn">File /media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py:222,</span> in <span class="ni">CV.train</span><span class="nt">(net, train_iter, test_iter, loss, trainer, num_epochs, devices)</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=219&#39;</span><span class="o">&gt;</span><span class="mi">220</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_iter</span><span class="p">):</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=220&#39;</span><span class="o">&gt;</span><span class="mi">221</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">timer</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="o">--&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=221&#39;</span><span class="o">&gt;</span><span class="mi">222</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">l</span><span class="p">,</span> <span class="n">acc</span> <span class="o">=</span> <span class="n">CV</span><span class="o">.</span><span class="n">train_batch</span><span class="p">(</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=222&#39;</span><span class="o">&gt;</span><span class="mi">223</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>         <span class="n">net</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">trainer</span><span class="p">,</span> <span class="n">devices</span><span class="p">)</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=223&#39;</span><span class="o">&gt;</span><span class="mi">224</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">metric</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">acc</span><span class="p">,</span> <span class="n">labels</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">labels</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=224&#39;</span><span class="o">&gt;</span><span class="mi">225</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>

<span class="nn">File /media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py:200,</span> in <span class="ni">CV.train_batch</span><span class="nt">(net, X, y, loss, trainer, devices)</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=197&#39;</span><span class="o">&gt;</span><span class="mi">198</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=198&#39;</span><span class="o">&gt;</span><span class="mi">199</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="o">--&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=199&#39;</span><span class="o">&gt;</span><span class="mi">200</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=200&#39;</span><span class="o">&gt;</span><span class="mi">201</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">trainer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///media/pc/data/4tb/xinet/web/pytorch-book/docs/utils/xinet.py?line=201&#39;</span><span class="o">&gt;</span><span class="mi">202</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">train_loss_sum</span> <span class="o">=</span> <span class="n">l</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="nn">File ~/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/_tensor.py:363,</span> in <span class="ni">Tensor.backward</span><span class="nt">(self, gradient, retain_graph, create_graph, inputs)</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/_tensor.py?line=353&#39;</span><span class="o">&gt;</span><span class="mi">354</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="k">if</span> <span class="n">has_torch_function_unary</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/_tensor.py?line=354&#39;</span><span class="o">&gt;</span><span class="mi">355</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="k">return</span> <span class="n">handle_torch_function</span><span class="p">(</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/_tensor.py?line=355&#39;</span><span class="o">&gt;</span><span class="mi">356</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>         <span class="n">Tensor</span><span class="o">.</span><span class="n">backward</span><span class="p">,</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/_tensor.py?line=356&#39;</span><span class="o">&gt;</span><span class="mi">357</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>         <span class="p">(</span><span class="bp">self</span><span class="p">,),</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/_tensor.py?line=360&#39;</span><span class="o">&gt;</span><span class="mi">361</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>         <span class="n">create_graph</span><span class="o">=</span><span class="n">create_graph</span><span class="p">,</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/_tensor.py?line=361&#39;</span><span class="o">&gt;</span><span class="mi">362</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>         <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
<span class="o">--&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/_tensor.py?line=362&#39;</span><span class="o">&gt;</span><span class="mi">363</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradient</span><span class="p">,</span> <span class="n">retain_graph</span><span class="p">,</span> <span class="n">create_graph</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>

<span class="nn">File ~/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/__init__.py:173,</span> in <span class="ni">backward</span><span class="nt">(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/__init__.py?line=167&#39;</span><span class="o">&gt;</span><span class="mi">168</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">retain_graph</span> <span class="o">=</span> <span class="n">create_graph</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/__init__.py?line=169&#39;</span><span class="o">&gt;</span><span class="mi">170</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="c1"># The reason we repeat same the comment below is that</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/__init__.py?line=170&#39;</span><span class="o">&gt;</span><span class="mi">171</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="c1"># some Python versions print out the first line of a multi-line function</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/__init__.py?line=171&#39;</span><span class="o">&gt;</span><span class="mi">172</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="c1"># calls in the traceback and some print out the last line</span>
<span class="o">--&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/__init__.py?line=172&#39;</span><span class="o">&gt;</span><span class="mi">173</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">Variable</span><span class="o">.</span><span class="n">_execution_engine</span><span class="o">.</span><span class="n">run_backward</span><span class="p">(</span>  <span class="c1"># Calls into the C++ engine to run the backward pass</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/__init__.py?line=173&#39;</span><span class="o">&gt;</span><span class="mi">174</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">tensors</span><span class="p">,</span> <span class="n">grad_tensors_</span><span class="p">,</span> <span class="n">retain_graph</span><span class="p">,</span> <span class="n">create_graph</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/__init__.py?line=174&#39;</span><span class="o">&gt;</span><span class="mi">175</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">allow_unreachable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">accumulate_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nn">File ~/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/function.py:253,</span> in <span class="ni">BackwardCFunction.apply</span><span class="nt">(self, *args)</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/function.py?line=248&#39;</span><span class="o">&gt;</span><span class="mi">249</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Implementing both &#39;backward&#39; and &#39;vjp&#39; for a custom &quot;</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/function.py?line=249&#39;</span><span class="o">&gt;</span><span class="mi">250</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>                        <span class="s2">&quot;Function is not allowed. You should only implement one &quot;</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/function.py?line=250&#39;</span><span class="o">&gt;</span><span class="mi">251</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>                        <span class="s2">&quot;of them.&quot;</span><span class="p">)</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/function.py?line=251&#39;</span><span class="o">&gt;</span><span class="mi">252</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">user_fn</span> <span class="o">=</span> <span class="n">vjp_fn</span> <span class="k">if</span> <span class="n">vjp_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">Function</span><span class="o">.</span><span class="n">vjp</span> <span class="k">else</span> <span class="n">backward_fn</span>
<span class="o">--&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/autograd/function.py?line=252&#39;</span><span class="o">&gt;</span><span class="mi">253</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="k">return</span> <span class="n">user_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>

<span class="nn">File ~/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:34,</span> in <span class="ni">Broadcast.backward</span><span class="nt">(ctx, *grad_outputs)</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/_functions.py?line=31&#39;</span><span class="o">&gt;</span><span class="mi">32</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="nd">@staticmethod</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/_functions.py?line=32&#39;</span><span class="o">&gt;</span><span class="mi">33</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="o">*</span><span class="n">grad_outputs</span><span class="p">):</span>
<span class="o">---&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/_functions.py?line=33&#39;</span><span class="o">&gt;</span><span class="mi">34</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="k">return</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span> <span class="o">+</span> <span class="n">ReduceAddCoalesced</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">input_device</span><span class="p">,</span> <span class="n">ctx</span><span class="o">.</span><span class="n">num_inputs</span><span class="p">,</span> <span class="o">*</span><span class="n">grad_outputs</span><span class="p">)</span>

<span class="nn">File ~/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:45,</span> in <span class="ni">ReduceAddCoalesced.forward</span><span class="nt">(ctx, destination, num_inputs, *grads)</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/_functions.py?line=40&#39;</span><span class="o">&gt;</span><span class="mi">41</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">ctx</span><span class="o">.</span><span class="n">target_gpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">grads</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">grads</span><span class="p">),</span> <span class="n">num_inputs</span><span class="p">)]</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/_functions.py?line=42&#39;</span><span class="o">&gt;</span><span class="mi">43</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="n">grads_</span> <span class="o">=</span> <span class="p">[</span><span class="n">grads</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span> <span class="o">+</span> <span class="n">num_inputs</span><span class="p">]</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/_functions.py?line=43&#39;</span><span class="o">&gt;</span><span class="mi">44</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>           <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">grads</span><span class="p">),</span> <span class="n">num_inputs</span><span class="p">)]</span>
<span class="o">---&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/_functions.py?line=44&#39;</span><span class="o">&gt;</span><span class="mi">45</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="k">return</span> <span class="n">comm</span><span class="o">.</span><span class="n">reduce_add_coalesced</span><span class="p">(</span><span class="n">grads_</span><span class="p">,</span> <span class="n">destination</span><span class="p">)</span>

<span class="nn">File ~/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py:143,</span> in <span class="ni">reduce_add_coalesced</span><span class="nt">(inputs, destination, buffer_size)</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=140&#39;</span><span class="o">&gt;</span><span class="mi">141</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="k">for</span> <span class="n">chunks</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">itrs</span><span class="p">):</span>
<span class="nn">    &lt;a href=&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=141&#39;&gt;142&lt;/a&gt;     flat_tensors = [_flatten_dense_tensors(chunk) for chunk</span> in <span class="ni">chunks]  # </span><span class="nt">(num_gpus,)</span>
<span class="o">--&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=142&#39;</span><span class="o">&gt;</span><span class="mi">143</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">flat_result</span> <span class="o">=</span> <span class="n">reduce_add</span><span class="p">(</span><span class="n">flat_tensors</span><span class="p">,</span> <span class="n">destination</span><span class="p">)</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=143&#39;</span><span class="o">&gt;</span><span class="mi">144</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">_unflatten_dense_tensors</span><span class="p">(</span><span class="n">flat_result</span><span class="p">,</span> <span class="n">chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=144&#39;</span><span class="o">&gt;</span><span class="mi">145</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>         <span class="c1"># The unflattened tensors do not share storage, and we don&#39;t expose</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=145&#39;</span><span class="o">&gt;</span><span class="mi">146</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>         <span class="c1"># base flat tensor anyways, so give them different version counters.</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=146&#39;</span><span class="o">&gt;</span><span class="mi">147</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>         <span class="c1"># See NOTE [ Version Counter in comm.*_coalesced ]</span>
    <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=147&#39;</span><span class="o">&gt;</span><span class="mi">148</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>         <span class="n">output</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>

<span class="nn">File ~/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py:96,</span> in <span class="ni">reduce_add</span><span class="nt">(inputs, destination)</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=93&#39;</span><span class="o">&gt;</span><span class="mi">94</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="k">if</span> <span class="n">nccl</span><span class="o">.</span><span class="n">is_available</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=94&#39;</span><span class="o">&gt;</span><span class="mi">95</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">result</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">root_index</span><span class="p">])</span>
<span class="o">---&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=95&#39;</span><span class="o">&gt;</span><span class="mi">96</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">nccl</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">output</span><span class="o">=</span><span class="n">result</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="n">root_index</span><span class="p">)</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=96&#39;</span><span class="o">&gt;</span><span class="mi">97</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="k">else</span><span class="p">:</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/nn/parallel/comm.py?line=97&#39;</span><span class="o">&gt;</span><span class="mi">98</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">destination_device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="n">root_index</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">destination</span><span class="p">)</span>

<span class="nn">File ~/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py:72,</span> in <span class="ni">reduce</span><span class="nt">(inputs, output, root, op, streams, comms, outputs)</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py?line=64&#39;</span><span class="o">&gt;</span><span class="mi">65</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="k">def</span> <span class="nf">reduce</span><span class="p">(</span><span class="n">inputs</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py?line=65&#39;</span><span class="o">&gt;</span><span class="mi">66</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>            <span class="n">output</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py?line=66&#39;</span><span class="o">&gt;</span><span class="mi">67</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>            <span class="n">root</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
   <span class="p">(</span><span class="o">...</span><span class="p">)</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py?line=69&#39;</span><span class="o">&gt;</span><span class="mi">70</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>            <span class="n">comms</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py?line=70&#39;</span><span class="o">&gt;</span><span class="mi">71</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>            <span class="n">outputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="o">---&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py?line=71&#39;</span><span class="o">&gt;</span><span class="mi">72</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">_check_sequence_type</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py?line=72&#39;</span><span class="o">&gt;</span><span class="mi">73</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="n">_output</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py?line=73&#39;</span><span class="o">&gt;</span><span class="mi">74</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="k">if</span> <span class="n">outputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>

<span class="nn">File ~/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py:51,</span> in <span class="ni">_check_sequence_type</span><span class="nt">(inputs)</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py?line=49&#39;</span><span class="o">&gt;</span><span class="mi">50</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span> <span class="k">def</span> <span class="nf">_check_sequence_type</span><span class="p">(</span><span class="n">inputs</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="o">---&gt;</span> <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py?line=50&#39;</span><span class="o">&gt;</span><span class="mi">51</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>     <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">collections</span><span class="o">.</span><span class="n">Container</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
     <span class="o">&lt;</span><span class="n">a</span> <span class="n">href</span><span class="o">=</span><span class="s1">&#39;file:///home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/cuda/nccl.py?line=51&#39;</span><span class="o">&gt;</span><span class="mi">52</span><span class="o">&lt;/</span><span class="n">a</span><span class="o">&gt;</span>         <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;Inputs should be a collection of tensors&quot;</span><span class="p">)</span>

<span class="ne">AttributeError</span>: module &#39;collections&#39; has no attribute &#39;Container&#39;
</pre></div>
</div>
<img alt="../../../_images/basic_14_1.svg" src="../../../_images/basic_14_1.svg" /></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_ft</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_ft</span><span class="p">,</span>
                       <span class="n">loader</span><span class="p">,</span>
                       <span class="n">criterion</span><span class="p">,</span>
                       <span class="n">optimizer_ft</span><span class="p">,</span>
                       <span class="n">exp_lr_scheduler</span><span class="p">,</span>
                       <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
                       <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">xs</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">loader</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">]:</span>
    <span class="k">break</span>

<span class="n">MT</span> <span class="o">=</span> <span class="n">ModuleTool</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="n">MT</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">model_ft</span><span class="p">,</span> <span class="n">loader</span><span class="o">.</span><span class="n">class_names</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span>
          <span class="n">num_rows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_cols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id2">
<h2>ConvNet 作为固定的特征提取器<a class="headerlink" href="#id2" title="永久链接至标题">¶</a></h2>
<p>在这里，需要冻结除了最后一层之外的所有网络。需要设置 <code class="docutils literal notranslate"><span class="pre">requires_grad</span> <span class="pre">=</span> <span class="pre">False</span></code> 来冻结参数，这样梯度就不会在 <code class="docutils literal notranslate"><span class="pre">backward()</span></code> 中计算出来。</p>
<p>也可以阅读 <a class="reference external" href="https://pytorch.org/docs/notes/autograd.html#excluding-subgraphs-from-backward">excluding-subgraphs-from-backward</a> 了解更多内容。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_conv</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># 新构造模块的参数默认为 requires_grad=True</span>
<span class="n">num_ftrs</span> <span class="o">=</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="n">model_conv</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_ftrs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">model_conv</span> <span class="o">=</span> <span class="n">model_conv</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># 观察到只有最后一层的参数被优化，而不是之前。</span>
<span class="n">optimizer_conv</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_conv</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># Decay LR by a factor of 0.1 every 7 epochs</span>
<span class="n">exp_lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_conv</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p class="rubric">训练和评估</p>
<p>在 CPU 上，与之前的场景相比，这将花费大约一半的时间。这是预期的，因为梯度不需要计算的大多数网络。但是，forward 确实需要计算。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">CV</span><span class="o">.</span><span class="n">train_fine_tuning</span><span class="p">(</span><span class="n">model_conv</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">test_iter</span><span class="p">,</span>
                     <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                     <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
                     <span class="n">param_group</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># model_conv = train_model(model_conv, loader, criterion, optimizer_conv,</span>
<span class="c1">#                          exp_lr_scheduler, num_epochs=25, device=device)</span>
</pre></div>
</div>
</div>
</div>
<p class="rubric">可视化</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">xs</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">loader</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">]:</span>
    <span class="k">break</span>

<span class="n">MT</span> <span class="o">=</span> <span class="n">ModuleTool</span><span class="p">(</span><span class="n">xs</span><span class="p">)</span>
<span class="n">MT</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">model_ft</span><span class="p">,</span> <span class="n">loader</span><span class="o">.</span><span class="n">class_names</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span>
          <span class="n">num_rows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_cols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ioff</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="index.html" title="上一页 页">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">上一页</p>
            <p class="prev-next-title">迁移学习</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="quantized.html" title="下一页 页">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">下一页</p>
        <p class="prev-next-title">量化计算机视觉分类</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
  <script src="../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022, xinetzone.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="last-updated">
最后更新于 2022-03-17, 08:50:24.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.4.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>