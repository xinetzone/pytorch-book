{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础\n",
    "\n",
    "参考：[Practical Quantization in PyTorch](https://pytorch.org/blog/quantization-in-practice/)\n",
    "\n",
    "{guilabel}`NN 量化目标`：运行更快、内存需求更低。\n",
    "\n",
    "- 量化源于信息压缩；在深度神经网络中，它指的是降低其权重和/或激活的数值精度。\n",
    "- 过度参数化的 DNN 有更多的 **自由度**，这使它们成为信息压缩的良好候选对象 {cite:ps}`gholami2021survey`。\n",
    "\n",
    "当量化模型时，通常会发生两件事——模型变得更小，运行效率更高。硬件供应商明确地允许更快地处理 8 位数据（而不是 32 位数据），从而获得更高的 **吞吐量** （throughput）。更小的模型具有更低的内存占用和功耗 {cite:ps}`krishnamoorthi2018quantizing`，这对于边缘部署至关重要。\n",
    "\n",
    "## 映射函数\n",
    "\n",
    "映射函数：将值从浮点数映射到整数空间的函数。常用的映射函数是由 $Q(r) = round(r/S + Z)$ 给出的线性变换，其中为 $r$ 为输入，$S, Z$ 为量化参数（quantization parameters）。为了重新转换为浮点空间，反函数由 $\\overline{r} = (Q(r) - Z) \\cdot S$ 给出（被称为 **反量化**，即 dequantization）。\n",
    "\n",
    "```{note}\n",
    "$\\overline{r} \\neq r$，它们之间的差异构成了量化误差。\n",
    "```\n",
    "\n",
    "## 量化参数\n",
    "\n",
    "映射函数由缩放因子 $S$ 和零点 $Z$ 所参数化。$S$ 仅仅是输入范围与输出范围的比值 $S = \\frac {\\beta - \\alpha}{\\beta_q - \\alpha_q}$。这里 $[\\alpha, \\beta]$ 是输入的裁剪（clipping）范围，即允许输入的边界。$[\\alpha_q, \\beta_q]$ 是它被映射到的量化输出空间的范围。对于 8 位量化，输出范围 $\\beta_q - \\alpha_q \\leq 2^8 -1$。$Z = -(\\frac {\\alpha}{S} - \\alpha_q)$ 作为偏置，以确保输入空间中的 $0$ 完全映射到量化空间中的 $0$。\n",
    "\n",
    "## 校准\n",
    "\n",
    "选择输入裁剪范围的过程称为 **校准** （calibration）。最简单的方法（也是 PyTorch 中的默认方法）是记录正在运行的最小值和最大值，并将它们赋值给 $\\alpha$ 和 $\\beta$。[TensorRT](https://docs.nvidia.com/deeplearning/tensorrt/pytorch-quantization-toolkit/docs/calib.html) 也使用熵最小化（KL 散度），均方误差最小化，或输入范围的百分位数。\n",
    "\n",
    "在 PyTorch 中，{class}`Observer <torch.ao.quantization.observer.ObserverBase>` 模块收集关于输入值的统计信息并计算 qparams $S,Z$。不同的校准方案会产生不同的量化输出，最好通过经验验证哪种方案最适合您的应用程序和体系结构。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.6123,  0.1598],\n",
       "         [ 0.4631, -0.1487],\n",
       "         [-0.1753,  1.1975]]),\n",
       " tensor([[-2.1246,  1.5558],\n",
       "         [-0.8172,  0.5080],\n",
       "         [ 0.3117, -0.8401]])]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.ao.quantization.observer import MinMaxObserver, MovingAverageMinMaxObserver, HistogramObserver\n",
    "\n",
    "# 设置输入\n",
    "C, L = 3, 2\n",
    "normal = torch.distributions.normal.Normal(0, 1)\n",
    "\n",
    "inputs = [normal.sample((C, L)),\n",
    "          normal.sample((C, L))]\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置观测："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "observers = [MinMaxObserver(), \n",
    "             MovingAverageMinMaxObserver(),\n",
    "             HistogramObserver()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算并查看量化参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxObserver (tensor([0.0144]), tensor([147], dtype=torch.int32))\n",
      "MovingAverageMinMaxObserver (tensor([0.0072]), tensor([88], dtype=torch.int32))\n",
      "HistogramObserver (tensor([0.0089]), tensor([79], dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "for obs in observers:\n",
    "    for x in inputs: obs(x)\n",
    "    print(obs.__class__.__name__, obs.calculate_qparams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仿射和对称量化方案\n",
    "\n",
    "仿射（affine）或非对称量化（asymmetric quantization）方案分配输入范围的最小和最大观测值。仿射方案通常提供更小的剪切范围，并且对于量化非负激活非常有用（如果你的输入张量永远都不是负的，你就不需要输入范围包含负值）。计算范围为 $\\alpha=\\min(r), \\beta = \\max(r)$。当用于权值张量 {cite:ps}`wu2020integer` 时，仿射量化会导致更昂贵的计算推理。\n",
    "\n",
    "对称量化（Symmetric quantization）方案将输入范围集中在 $0$ 附近，消除了计算零点偏置的需要。计算范围为 $-\\alpha=\\beta=\\max(|\\max(r)|,|\\min(r)|)$。\n",
    "\n",
    "对于倾斜的信号（如非负激活），这可能会导致糟糕的量化分辨率（quantization resolution），因为剪辑范围包括从未在输入中出现的值（参见下面的 pyplot）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_symmetric_range(x):\n",
    "    '''获取对称范围'''\n",
    "    beta = torch.max(x.max(), x.min().abs())\n",
    "    return -beta.item(), beta.item()\n",
    "\n",
    "\n",
    "def get_affine_range(x):\n",
    "    '''获取仿射范围'''\n",
    "    return x.min().item(), x.max().item()\n",
    "\n",
    "\n",
    "def plot(plt, data, scheme):\n",
    "    '''画出不同方案的分布'''\n",
    "    boundaries = get_affine_range(data) if scheme == 'affine' \\\n",
    "        else get_symmetric_range(data)\n",
    "    a, _, _ = plt.hist(data, density=True, bins=100)\n",
    "    ymin, ymax = np.quantile(a[a > 0], [0.25, 0.95])\n",
    "    plt.vlines(x=boundaries, ls='--', colors='purple', ymin=ymin, ymax=ymax)\n",
    "\n",
    "\n",
    "# 模拟激活和权重\n",
    "act = torch.distributions.pareto.Pareto(1, 10).sample((1, 1024))\n",
    "weights = torch.distributions.normal.Normal(0, 0.12).sample((3, 64, 7, 7)).flatten()\n",
    "\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "plot(axs[0, 0], act, 'affine')\n",
    "axs[0, 0].set_title(\"Activation, Affine-Quantized\")\n",
    "plot(axs[0, 1], act, 'symmetric')\n",
    "axs[0, 1].set_title(\"Activation, Symmetric-Quantized\")\n",
    "plot(axs[1, 0], weights, 'affine')\n",
    "axs[1, 0].set_title(\"Weights, Affine-Quantized\")\n",
    "plot(axs[1, 1], weights, 'symmetric')\n",
    "axs[1, 1].set_title(\"Weights, Symmetric-Quantized\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 PyTorch 中，你可以在初始化 `Observer` 时指定仿射或对称模式。注意，并非所有 `observer` 都支持这两种方案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qscheme: torch.per_tensor_affine | (tensor([0.0072]), tensor([88], dtype=torch.int32))\n",
      "Qscheme: torch.per_tensor_symmetric | (tensor([0.0094]), tensor([128]))\n"
     ]
    }
   ],
   "source": [
    "for qscheme in [torch.per_tensor_affine, torch.per_tensor_symmetric]:\n",
    "    obs = MovingAverageMinMaxObserver(qscheme=qscheme)\n",
    "    for x in inputs: obs(x)\n",
    "    print(f\"Qscheme: {qscheme} | {obs.calculate_qparams()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 逐张量和逐通道量化方案\n",
    "\n",
    "量化参数可以作为整体计算层的整个权值张量，也可以单独计算每个通道的权值张量。在每张量中，对层中的所有通道应用相同的剪切范围：\n",
    "\n",
    "![](images/tensor-quantization.png)\n",
    "\n",
    "对于权值量化，逐通道（Per-Channel）对称量化提供了更好的精度；逐张量（Per-Tensor）量化的性能很差，这可能是由于不同通道之间的转换权值与批量范数折叠（batchnorm folding） {cite:ps}`wu2020integer` 差异很大。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.0031, 0.0024, 0.0054]), tensor([200,  64,  34], dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization.observer import MovingAveragePerChannelMinMaxObserver\n",
    "# 计算全部 `C` 通道的 qparams\n",
    "obs = MovingAveragePerChannelMinMaxObserver(ch_axis=0)\n",
    "for x in inputs: obs(x)\n",
    "print(obs.calculate_qparams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 后端引擎\n",
    "\n",
    "目前，量化算子通过 [FBGEMM 后端](https://github.com/pytorch/FBGEMM) 在 x86 机器上运行，或者在 ARM 机器上使用 [QNNPACK](https://github.com/pytorch/QNNPACK) 原语。服务器 GPU 的后端支持（通过 TensorRT 和 cuDNN）即将推出。了解更多关于将量化扩展到自定义后端：[RFC-0019](https://github.com/pytorch/rfcs/blob/master/RFC-0019-Extending-PyTorch-Quantization-to-Custom-Backends.md)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.qconfig import get_default_qconfig\n",
    "backend = 'fbgemm' # if x86 else 'qnnpack'\n",
    "qconfig = get_default_qconfig(backend)  \n",
    "torch.backends.quantized.engine = backend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `QConfig`\n",
    "\n",
    "{class}`~torch.ao.quantization.qconfig.QConfig` NamedTuple 存储用于量化激活和权重的 Observer 和量化方案。\n",
    "\n",
    "一定要传递 `Observer` 类（而不是实例），或者可以返回 `Observer` 实例的可调用对象。使用 {func}`with_args` 覆盖默认参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.qconfig import QConfig\n",
    "\n",
    "my_qconfig = QConfig(\n",
    "  activation=MovingAverageMinMaxObserver.with_args(qscheme=torch.per_tensor_affine),\n",
    "  weight=MovingAveragePerChannelMinMaxObserver.with_args(qscheme=torch.qint8)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MovingAverageMinMaxObserver'>, qscheme=torch.per_tensor_affine){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver'>, qscheme=torch.qint8){})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_qconfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在 PyTorch 中\n",
    "\n",
    "PyTorch 允许您使用几种不同的方式来量化您的模型：\n",
    "\n",
    "- Eager 模式 v/s FX Graph 模式：如果你更喜欢灵活但手动的，或受限的自动过程\n",
    "- 静态 v/s 动态：如果量化激活（层的输出）的 `qparams` 为所有输入预先计算，或对每个输入重新计算，\n",
    "- 量化感知训练（quantization-aware training） v/s 训练后量化（post-training quantization）：如果 `qparams` 是在有或没有重新训练的情况下计算的\n",
    "\n",
    "FX Graph Mode 自动融合符合条件的模块，插入 Quant/DeQuant stub，校准模型并返回量化模块——所有这些都是在两个方法调用中进行的——但仅适用于 [可符号跟踪](https://pytorch.org/docs/stable/fx.html#torch.fx.symbolic_trace) 的网络。 \n",
    "\n",
    "在 DNN 中，量化的合适候选对象是 FP32 权值（层参数）和激活（层输出）。量化权值可以减少模型的大小。量化激活通常会导致更快的推理。\n",
    "\n",
    "例如，50 层 ResNet 网络有近 2600 万个权值参数，在正向传程中计算近 1600 万个激活。\n",
    "\n",
    "### Post-Training Dynamic/Weight-only Quantization\n",
    "\n",
    "这里模型的权值是预量化的；在推理期间，激活是动态量化的。这是所有方法中最简单的一种，它在 {func}`~torch.ao.quantization.quantize.quantize_dynamic` 中有一行 API 调用。目前只支持线性和循环（LSTM、GRU、RNN）层进行动态量化。\n",
    "\n",
    "- 可以导致更高的精度，因为每个输入的裁剪范围是精确校准的\n",
    "- 对于像 LSTM 和 Transformer 这样的模型，动态量化是首选的，因为从内存中写入/检索模型的权值会受制于带宽\n",
    "- 在运行时对每个层的激活进行校准和量化会增加计算开销。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 小 model\n",
    "def create_model():\n",
    "  m = nn.Sequential(\n",
    "  nn.Conv2d(2, 64, (8,)),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(16,10),\n",
    "  nn.LSTM(10, 10))\n",
    "\n",
    "  m.eval()\n",
    "  return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{rubric} eager 模式\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization.quantize import quantize_dynamic\n",
    "\n",
    "m = create_model()\n",
    "model_quantized = quantize_dynamic(\n",
    "    model=m, qconfig_spec={nn.LSTM, nn.Linear}, dtype=torch.qint8, inplace=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{rubric} FX 模式\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pc/xinet/anaconda3/envs/torchx/lib/python3.10/site-packages/torch/ao/quantization/fx/quantization_patterns.py:630: UserWarning: dtype combination: (torch.float32, torch.qint8, torch.quint8) is not supported by Conv supported dtype combinations are: [(torch.quint8, torch.qint8, None)]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization import quantize_fx\n",
    "from torch.ao.quantization.qconfig import default_dynamic_qconfig\n",
    "\n",
    "m = create_model()\n",
    "# 空键表示应用于所有模块的默认值\n",
    "qconfig_dict = {\"\": default_dynamic_qconfig}\n",
    "model_prepared = quantize_fx.prepare_fx(m, qconfig_dict)\n",
    "model_quantized = quantize_fx.convert_fx(model_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Training Static Quantization (PTQ)\n",
    "\n",
    "PTQ 也预量化模型权重，但不是动态校准激活，而是使用验证数据对剪切范围进行预校准和固定（“静态”）。在推理过程中，激活在运算之间保持量化精度。大约 100 个小批次的代表性数据就足以校准观测者。为了方便起见，下面的例子在校准中使用了随机数据——在应用程序中使用随机数据将导致错误的 `qparams`。\n",
    "\n",
    "![](images/ptq-flowchart.svg)\n",
    "\n",
    "[模块融合](https://pytorch.org/tutorials/recipes/fuse.html) 将多个顺序模块（如：`[Conv2d, BatchNorm, ReLU]`）组合成一个。融合模块意味着编译器只需要运行一个内核而不是多个；这可以通过减少量化误差来提高速度和准确性。\n",
    "\n",
    "- 静态量化比动态量化具有更快的推理速度，因为它消除了层之间的 float<->int 转换成本。\n",
    "- 静态量化模型可能需要定期重新校准，以保持对分布漂移的鲁棒性。\n",
    "\n",
    "静态量化模型包括以下步骤：\n",
    "\n",
    "- 融合模块\n",
    "- 插入 Quant/DeQuant 存根\n",
    "- 准备融合模块（在层前和层后插入观察者）\n",
    "- 校准准备好的模块（传递代表数据）\n",
    "- 转换校准模块（替换为量化版本）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quantization import quantize_fx\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "backend = \"fbgemm\"  # 运行在x86 CPU 上。如果在ARM上运行，使用“qnnpack”。\n",
    "\n",
    "m = nn.Sequential(\n",
    "    nn.Conv2d(2, 64, 3),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 128, 3),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 急切的模式\n",
    "\n",
    "**融合**：就地融合用所述融合模块替换所述序列中的第一个模块，其余用相同模块替换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fuse first Conv-ReLU pair\n",
    "torch.quantization.fuse_modules(m, ['0', '1'], inplace=True)\n",
    "# fuse second Conv-ReLU pair\n",
    "torch.quantization.fuse_modules(m, ['2', '3'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "插入 stub："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(torch.quantization.QuantStub(),\n",
    "                  *m,\n",
    "                  torch.quantization.DeQuantStub())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.quantization.prepare(m, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**校准**：为了方便起见，这个例子使用了随机数据。使用代表性（验证）数据代替。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.inference_mode(): # PyTorch 1.9\n",
    "with torch.no_grad():\n",
    "    for _ in range(10):\n",
    "        x = torch.rand(1, 2, 28, 28)\n",
    "        m(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.quantization.convert(m, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 字节，而不是 FP32 的 4 字节\n",
    "print(m[1].weight().element_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FX GRAPH\n",
    "\n",
    "```python\n",
    "from torch.quantization import quantize_fx\n",
    "m.eval()\n",
    "qconfig_dict = {\"\": torch.quantization.get_default_qconfig(backend)}\n",
    "# 准备\n",
    "model_prepared = quantize_fx.prepare_fx(model_to_quantize, qconfig_dict)\n",
    "# Calibrate - Use representative (validation) data.\n",
    "with torch.inference_mode():\n",
    "  for _ in range(10):\n",
    "    x = torch.rand(1,2,28, 28)\n",
    "    model_prepared(x)\n",
    "# quantize\n",
    "model_quantized = quantize_fx.convert_fx(model_prepared)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization-aware Training (QAT)\n",
    "\n",
    "![](images/qat-flowchart.svg)\n",
    "\n",
    "PTQ 方法对于大型模型非常好，但在较小的模型中准确性会受到影响。当然，这是由于将 FP32 的模型调整到 INT8 域时的数值精度损失。\n",
    "\n",
    "QAT 通过在训练损失中包含量化误差来解决这个问题，因此训练一个 INT8-first 模型。\n",
    "\n",
    "![](images/ptq-qat.png)\n",
    "\n",
    "所有的权重和偏置都存储在 FP32 中，反向传播照常发生。然而在正向传递中，量化是通过 `FakeQuantize` 模块进行内部模拟的。它们之所以被称为假的，是因为它们对数据进行量化和立即反量化，并添加与量化推理过程中可能遇到的类似的量化噪声。因此，最终的损失可以解释任何预期的量化误差。在此基础上进行优化，可以使模型在损失函数中识别出更宽的区域，并识别出 FP32 参数，这样量化到 INT8 不会显著影响精度。\n",
    "\n",
    "[![](images/qat-fake-quantization.png)](https://developer.nvidia.com/blog/achieving-fp32-accuracy-for-int8-inference-using-quantization-aware-training-with-tensorrt)\n",
    "\n",
    "- QAT 比 PTQ 具有更高的精度。\n",
    "- Qparams 可以在模型训练期间学习，以获得更细粒度的准确性（参见 [LearnableFakeQuantize](https://github.com/pytorch/pytorch/blob/master/torch/ao/quantization/_learnable_fake_quantize.py)）。\n",
    "- 在 QAT 中，重新训练一个模型的计算成本可以达到几百个 epoch。{cite:ps}`gholami2021survey`\n",
    "\n",
    "除了在将模型实际转换为量化版本之前的训练循环之外，QAT 遵循与 PTQ 相同的步骤："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# 运行在 x86 CPU 上。如果在 ARM 上运行，使用 \"qnnpack\"。\n",
    "backend = \"fbgemm\"  \n",
    "\n",
    "m = nn.Sequential(\n",
    "    nn.Conv2d(2, 64, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 128, 8),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "融合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.quantization.fuse_modules(m, ['0','1'], inplace=True) # 融合第一对 Conv-ReLU\n",
    "torch.quantization.fuse_modules(m, ['2','3'], inplace=True) # 融合第二对 Conv-ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "插入存根（打桩）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sequential(torch.quantization.QuantStub(),\n",
    "                  *m,\n",
    "                  torch.quantization.DeQuantStub())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.train()\n",
    "m.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.quantization.prepare_qat(m, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "循环训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "opt = torch.optim.SGD(m.parameters(), lr=0.1)\n",
    "def loss_fn(out, tgt): return torch.pow(tgt-out, 2).mean()\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  x = torch.rand(10, 2, 24, 24)\n",
    "  out = m(x)\n",
    "  loss = loss_fn(out, torch.rand_like(out))\n",
    "  opt.zero_grad()\n",
    "  loss.backward()\n",
    "  opt.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.eval()\n",
    "torch.quantization.convert(m, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 敏感性分析\n",
    "\n",
    "并不是所有层对量化的响应都是一样的，有些层对精度下降比其他层更敏感。确定最优的层组合以最小化精度下降是非常耗时的，因此 {cite:ps}`wu2020integer` 建议进行一次一次的灵敏度分析，以确定哪些层最敏感，并在这些层上保持 FP32 的精度。在他们的实验中，跳过 2 个 conv 层（在 MobileNet v1 的 28 个 conv 层中）使他们接近 FP32 的精度。使用 FX Graph 模式，可以创建自定义 `qconfigs` 来轻松做到这一点。\n",
    "\n",
    "```python\n",
    "# ONE-AT-A-TIME SENSITIVITY ANALYSIS \n",
    "\n",
    "for quantized_layer, _ in model.named_modules():\n",
    "  print(\"Only quantizing layer: \", quantized_layer)\n",
    "\n",
    "  # The module_name key allows module-specific qconfigs. \n",
    "  qconfig_dict = {\"\": None, \n",
    "  \"module_name\":[(quantized_layer, torch.quantization.get_default_qconfig(backend))]}\n",
    "\n",
    "  model_prepared = quantize_fx.prepare_fx(model, qconfig_dict)\n",
    "  # calibrate\n",
    "  model_quantized = quantize_fx.convert_fx(model_prepared)\n",
    "  # evaluate(model)\n",
    "```\n",
    "\n",
    "另一种方法是比较 FP32 和 INT8 层的统计数据；常用的度量有 SQNR（信号量化噪声比，即 Signal to Quantized Noise Ratio）和均方误差（Mean-Squre-Error）。这种比较分析也有助于指导进一步的优化。\n",
    "\n",
    "![](images/compare_output_ns.png)\n",
    "\n",
    "PyTorch 在数值套件下提供了帮助进行此分析的工具。从完整的教程中了解更多关于使用 [Numeric Suite](https://pytorch.org/tutorials/prototype/numeric_suite_tutorial.html) 的信息。\n",
    "\n",
    "```python\n",
    "# extract from https://pytorch.org/tutorials/prototype/numeric_suite_tutorial.html\n",
    "import torch.quantization._numeric_suite as ns\n",
    "\n",
    "def SQNR(x, y):\n",
    "    # Higher is better\n",
    "    Ps = torch.norm(x)\n",
    "    Pn = torch.norm(x-y)\n",
    "    return 20*torch.log10(Ps/Pn)\n",
    "\n",
    "wt_compare_dict = ns.compare_weights(fp32_model.state_dict(), int8_model.state_dict())\n",
    "for key in wt_compare_dict:\n",
    "    print(key, compute_error(wt_compare_dict[key]['float'], wt_compare_dict[key]['quantized'].dequantize()))\n",
    "\n",
    "act_compare_dict = ns.compare_model_outputs(fp32_model, int8_model, input_data)\n",
    "for key in act_compare_dict:\n",
    "    print(key, compute_error(act_compare_dict[key]['float'][0], act_compare_dict[key]['quantized'][0].dequantize()))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对您工作流程的建议\n",
    "\n",
    "![](images/quantization-flowchart2.png)\n",
    "\n",
    "要点：\n",
    "\n",
    "- 大（10M+ 参数）模型对量化误差更具鲁棒性。\n",
    "- 从 FP32 检查点量化模型比从零开始训练 INT8 模型提供了更好的 accuracy。\n",
    "- 分析模型运行时是可选的，但它可以帮助识别阻碍推理的层。\n",
    "- 动态量化是一个简单的第一步，特别是当您的模型有许多线性或递归层时。\n",
    "- 使用逐通道对称量化借由 `MinMax` 观测者量化权重。使用逐张量仿射量化借由 `MovingAverageMinMax` 观测者量化激活。\n",
    "- 使用诸如 SQNR 之类的度量来确定哪些层最容易受到量化误差的影响。关闭这些层上的量化。\n",
    "- 使用 QAT 对原始训练调度的大约 $10\\%$ 进行微调，退火学习率（annealing learning rate）调度从初始训练学习率的 $1\\%$ 开始。\n",
    "- 如果上面的工作流程不适合你，我们想知道更多。发布一个包含你的代码细节的帖子（模型架构，准确性指标，尝试过的技术）。请抄送 [@suraj.pt](https://discuss.pytorch.org/u/suraj.pt/)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
