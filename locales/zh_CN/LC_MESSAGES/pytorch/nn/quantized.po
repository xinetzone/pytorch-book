# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022, xinetzone
# This file is distributed under the same license as the Pytorch Book
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Pytorch Book \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2022-03-22 16:05+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../../api/pytorch/nn/quantized.rst:2
msgid "torch.nn.quantized"
msgstr ""

#: ../../../api/pytorch/nn/quantized.rst:15:<autosummary>:1
msgid ":py:obj:`FloatFunctional <torch.nn.quantized.FloatFunctional>`"
msgstr ""

#: ../../../api/pytorch/nn/quantized.rst:15:<autosummary>:1
msgid "State collector class for float operations."
msgstr ""

#: ../../../api/pytorch/nn/quantized.rst:15:<autosummary>:1
msgid ":py:obj:`FXFloatFunctional <torch.nn.quantized.FXFloatFunctional>`"
msgstr ""

#: ../../../api/pytorch/nn/quantized.rst:15:<autosummary>:1
msgid ""
"module to replace FloatFunctional module before FX graph mode "
"quantization, since activation_post_process will be inserted in top level"
" module directly"
msgstr ""

#: ../../../api/pytorch/nn/quantized.rst:15:<autosummary>:1
msgid ":py:obj:`QFunctional <torch.nn.quantized.QFunctional>`"
msgstr ""

#: ../../../api/pytorch/nn/quantized.rst:15:<autosummary>:1
msgid "Wrapper class for quantized operations."
msgstr ""

